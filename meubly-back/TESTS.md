# Tests pour Meubly Backend

## ğŸ“‹ Vue d'ensemble

Ce projet utilise une approche de test complÃ¨te avec :
- **Tests unitaires** : Vitest
- **Tests d'intÃ©gration** : Vitest + Supertest
- **Tests de services** : Vitest avec mocks

## ğŸš€ Installation des dÃ©pendances

```bash
npm install
```

## ğŸ§ª Tests unitaires

### ExÃ©cution des tests unitaires

```bash
# Lancer les tests en mode watch
npm run test

# Lancer les tests une seule fois
npm run test:run

# Lancer les tests avec couverture de code
npm run test:coverage

# Lancer les tests en mode watch
npm run test:watch
```

### Structure des tests unitaires

```
tests/
â”œâ”€â”€ unit/
â”‚   â””â”€â”€ furnitureService.test.js  # Tests du service de meubles
â””â”€â”€ integration/
    â””â”€â”€ furnitureRoutes.test.js   # Tests d'intÃ©gration des routes
```

### Exemples de tests

#### Test d'un service
```javascript
describe('FurnitureService', () => {
  it('should return furniture when found', async () => {
    const mockFurniture = {
      id: 1,
      name: 'Chaise de bureau',
      price: 150
    };

    const { supabase } = await import('../../supabase.js');
    supabase.from.mockReturnValue({
      select: vi.fn(() => ({
        eq: vi.fn(() => ({
          single: vi.fn(() => mockFurniture)
        }))
      }))
    });

    const result = await furnitureService.getFurnitureById(1);
    expect(result).toEqual(mockFurniture);
  });
});
```

## ğŸ”„ Tests d'intÃ©gration

### ExÃ©cution des tests d'intÃ©gration

```bash
# Les tests d'intÃ©gration sont inclus dans les tests unitaires
npm run test:run
```

### Exemples de tests d'intÃ©gration

#### Test d'une route API
```javascript
describe('Furniture Routes Integration Tests', () => {
  it('should return all furniture', async () => {
    const response = await request(server)
      .get('/api/v1/furnitures')
      .expect(200);

    expect(response.body).toBeInstanceOf(Array);
    expect(response.headers['content-type']).toMatch(/application\/json/);
  });
});
```

## ğŸ“Š Couverture de code

### GÃ©nÃ©rer un rapport de couverture

```bash
npm run test:coverage
```

Le rapport sera gÃ©nÃ©rÃ© avec :
- Statistiques par fichier
- Lignes couvertes/non couvertes
- Branches couvertes/non couvertes

## ğŸ› ï¸ Configuration

### Configuration Vitest

CrÃ©ez un fichier `vitest.config.js` :

```javascript
import { defineConfig } from 'vitest/config'

export default defineConfig({
  test: {
    environment: 'node',
    globals: true,
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html'],
      exclude: [
        'node_modules/',
        'tests/',
        '**/*.config.js',
        'dist/'
      ]
    }
  }
})
```

### Variables d'environnement pour les tests

CrÃ©ez un fichier `.env.test` :

```env
NODE_ENV=test
PORT=5001
SUPABASE_URL=your_test_supabase_url
SUPABASE_ANON_KEY=your_test_supabase_key
```

## ğŸš¨ Bonnes pratiques

### Tests unitaires
- Testez une fonctionnalitÃ© Ã  la fois
- Utilisez des mocks pour les dÃ©pendances externes (Supabase, etc.)
- Nommez vos tests de maniÃ¨re descriptive
- VÃ©rifiez les cas d'erreur et de succÃ¨s

### Tests d'intÃ©gration
- Testez les routes API complÃ¨tes
- VÃ©rifiez les codes de statut HTTP
- Testez les rÃ©ponses JSON
- VÃ©rifiez les headers de rÃ©ponse

### Organisation
- Gardez les tests proches du code testÃ©
- Utilisez des fixtures pour les donnÃ©es de test
- Documentez les mocks complexes
- Maintenez les tests Ã  jour

## ğŸ” Debugging

### Debugger les tests

```bash
# Mode debug avec Vitest
npm run test -- --reporter=verbose

# Mode watch avec logs
npm run test -- --reporter=verbose --watch

# Lancer un test spÃ©cifique
npm run test -- furnitureService.test.js
```

## ğŸ“ˆ IntÃ©gration CI/CD

### GitHub Actions

Exemple de workflow pour les tests backend :

```yaml
name: Backend Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '18'
      - run: npm ci
      - run: npm run test:run
      - run: npm run test:coverage
```

## ğŸ¯ MÃ©triques de qualitÃ©

### Objectifs de couverture
- **Tests unitaires** : > 80%
- **Tests d'intÃ©gration** : > 70%
- **Services critiques** : > 90%

### Performance
- Tests unitaires : < 20 secondes
- Tests d'intÃ©gration : < 30 secondes
- Build complet : < 5 minutes

## ğŸ“š Ressources

- [Documentation Vitest](https://vitest.dev/)
- [Documentation Supertest](https://github.com/visionmedia/supertest)
- [Testing Node.js Applications](https://nodejs.org/en/docs/guides/testing-and-debugging/)
- [Express.js Testing](https://expressjs.com/en/advanced/best-practices-performance.html#testing)

## ğŸ”§ Mocks et stubs

### Mock de Supabase

```javascript
vi.mock('../../supabase.js', () => ({
  supabase: {
    from: vi.fn(() => ({
      select: vi.fn(() => ({
        eq: vi.fn(() => ({
          single: vi.fn()
        }))
      }))
    }))
  }
}));
```

### Mock de services externes

```javascript
// Mock d'un service de paiement
vi.mock('../../services/paymentService.js', () => ({
  processPayment: vi.fn(() => Promise.resolve({ success: true }))
}));
```

## ğŸš€ ExÃ©cution en production

### Tests avant dÃ©ploiement

```bash
# Pipeline de tests complet
npm run test:run && npm run test:coverage

# VÃ©rification de la couverture minimale
npm run test:coverage -- --coverage.threshold.lines=80
```

### IntÃ©gration avec les outils de qualitÃ©

- **SonarQube** : Analyse de la qualitÃ© du code
- **Codecov** : Suivi de la couverture de code
- **GitHub Actions** : CI/CD automatisÃ©
